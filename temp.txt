# app/api/v1/endpoints/transcriptions.py

import os
import tempfile
import logging
from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Form
from pydantic import BaseModel
from sqlalchemy.orm import Session

from app.services.storage_service import storage_service
from app.services.diarization_service import diarize_file
from app.services.whisper_service import transcribe_full, transcribe_segment
from app.services.emotion_service import detect_emotion
from app.services.polishing_service import polish_text
from app.db.database import get_db
from app.models.audio_model import AudioTranscription
from app.api.auth.auth import get_current_user
from app.models.user_model import User

router = APIRouter(
    prefix="/api/v1",
    tags=["transcriptions"]
)
logger = logging.getLogger(__name__)

class SegmentOut(BaseModel):
    start: float
    end: float
    speaker: str
    text: str
    emotion: str

class TranscriptionResponse(BaseModel):
    id: int
    text: str
    audio_url: str
    language: str
    duration: float
    filename: str
    segments: list[SegmentOut]
    formatted_text: str
    speakers: list[str]
    overall_emotion: str
    polished_text: str

async def transcribe_audio_file(
    file: UploadFile,
    language: str = "kk",
    task: str = "transcribe",
    enable_diarization: bool = True,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
) -> TranscriptionResponse:
    """
    Функция для внутреннего вызова из chat_sessions.py
    Обрабатывает UploadFile точно так же, как POST-эндпоинт ниже.
    """
    # 1. Проверка типа файла
    if not file.filename.lower().endswith(('.mp3', '.wav', '.m4a', '.ogg', '.flac')):
        raise HTTPException(status_code=400, detail="Only audio files allowed")

    # 2. Загрузка на S3
    file_info = await storage_service.upload_file(file)

    # 3. Сохранение во временный файл
    suffix = os.path.splitext(file.filename)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        await file.seek(0)
        tmp.write(await file.read())
        temp_path = tmp.name

    segments_data: list[dict] = []
    speakers: list[str] = []
    overall_emotion = ""

    # 4. Диаризация и построчная обработка
    if enable_diarization:
        raw_segments = diarize_file(temp_path)
        for seg in raw_segments:
            if seg['speaker'] not in speakers:
                speakers.append(seg['speaker'])
            txt = transcribe_segment(temp_path, seg['start'], seg['end'], task=task)
            emotion = detect_emotion(temp_path)
            segments_data.append({
                "start":   seg['start'],
                "end":     seg['end'],
                "speaker": seg['speaker'],
                "text":    txt,
                "emotion": emotion
            })
        formatted = "\n".join(f"{s['speaker']}: {s['text']}" for s in segments_data)
        full_text = " ".join(s['text'] for s in segments_data)
    else:
        full_text = transcribe_full(temp_path, task=task)
        formatted = full_text
        overall_emotion = detect_emotion(temp_path)
        segments_data = []
        speakers = []

    os.unlink(temp_path)

    # 5. Полировка через GPT
    polished = polish_text(full_text, language)

    # 6. Сохранение в БД
    transcription = AudioTranscription(
        original_filename       = file_info["original_filename"],
        s3_filename             = file_info["s3_filename"],
        s3_url                  = file_info["s3_url"],
        file_size               = file_info["size"],
        duration                = None,
        language                = language,
        transcription           = full_text,
        formatted_transcription = formatted,
        speakers                = speakers,
        diarization_data        = segments_data,
        overall_emotion         = overall_emotion,
        polished_text           = polished
    )
    db.add(transcription)
    db.commit()
    db.refresh(transcription)

    return TranscriptionResponse(
        id               = transcription.id,
        text             = transcription.transcription,
        audio_url        = transcription.s3_url,
        language         = transcription.language,
        duration         = transcription.duration or 0.0,
        filename         = transcription.original_filename,
        segments         = transcription.diarization_data,
        formatted_text   = transcription.formatted_transcription,
        speakers         = transcription.speakers,
        overall_emotion  = transcription.overall_emotion,
        polished_text    = transcription.polished_text
    )

@router.post("/transcribe", response_model=TranscriptionResponse)
async def transcribe_endpoint(
    file: UploadFile = File(...),
    language: str = Form("kk"),
    task: str = Form("transcribe"),
    enable_diarization: bool = Form(True),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    # просто перенаправляем в общую функцию
    return await transcribe_audio_file(file, language, task, enable_diarization, db, current_user)
